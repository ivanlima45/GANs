# -*- coding: utf-8 -*-
"""CycleGAN Horse2Zebra

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qG-x4uwQ9IxnHRgq8Ex6lg7_yW19POgD
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x

# Commented out IPython magic to ensure Python compatibility.
from __future__ import division

import keras.backend as K
from keras.models import Model
from keras.layers import *
from keras.initializers import *
from keras.activations import relu

from keras.layers import Layer, InputSpec
from keras import initializers, regularizers, constraints

import tensorflow as tf
from keras.backend.tensorflow_backend import set_session

from PIL import Image, ImageEnhance, ImageOps
import numpy as np
import random

from keras.preprocessing.image import ImageDataGenerator
from PIL import Image, ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True
from glob import glob
from random import shuffle, randint
import numpy as np
from keras.utils import Sequence

from glob import glob

import os

'''if tf.test.is_gpu_available(
    cuda_only=False, min_cuda_compute_capability=None):

    tf.test.gpu_device_name()

    os.environ["CUDA_VISIBLE_DEVICES"]="1"

    config = tf.ConfigProto()
    config.gpu_options.allow_growth=True
    set_session(tf.Session(config=config))'''

import tensorflow as tf

#import wget
#import zipfile
#print("Downloading Dataset")
#ds = wget.download("https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/horse2zebra.zip")
#zf = zipfile.ZipFile(ds, 'r')
#zf.extractall("./datasets")
#zf.close()

# Non-random random
random.seed(0)

'''
Data Augmentation
'''
class BasicPolicy(object):
    def __init__(self, mirror_ratio = 0, flip_ratio = 0, color_change_ratio = 0, is_full_set_colors = False, add_noise_peak = 0.0, erase_ratio = -1.0):
        # Random color channel order
        from itertools import product, permutations
        self.indices = list(product([0,1,2], repeat = 3)) if is_full_set_colors else list(permutations(range(3), 3))
        self.indices.insert(0, [0,1,2]) # R,G,B
        self.add_noise_peak = add_noise_peak

        # Mirror and flip
        self.color_change_ratio = color_change_ratio
        self.mirror_ratio = mirror_ratio
        self.flip_ratio = flip_ratio

        # Erase
        self.erase_ratio = erase_ratio

    def __call__(self, img):

        # 0) Add poisson noise (e.g. choose peak value 20)
        if self.add_noise_peak > 0:
            PEAK = self.add_noise_peak
            img = np.random.poisson(np.clip(img, 0, 1) * PEAK) / PEAK

        # 1) Color change
        policy_idx = random.randint(0, len(self.indices) - 1)
        if random.uniform(0, 1) >= self.color_change_ratio:
            policy_idx = 0

        img = img[...,list(self.indices[policy_idx])]

        # 2) Mirror image
        if random.uniform(0, 1) <= self.mirror_ratio:
            img = img[...,::-1,:]

        # 3) Flip image vertically
        if random.uniform(0, 1) < self.flip_ratio:
            img = img[...,::-1,:,:]

        # 4) Erase random box
        if random.uniform(0, 1) < self.erase_ratio:
            img = self.eraser(img)

        return img

    def __repr__(self):
        return "Basic Policy"

    def eraser(self, input_img, p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=True):
        img_h, img_w, img_c = input_img.shape
        p_1 = np.random.rand()

        if p_1 > p:
            return input_img

        while True:
            s = np.random.uniform(s_l, s_h) * img_h * img_w
            r = np.random.uniform(r_1, r_2)
            w = int(np.sqrt(s / r))
            h = int(np.sqrt(s * r))
            left = np.random.randint(0, img_w)
            top = np.random.randint(0, img_h)

            if left + w <= img_w and top + h <= img_h:
                break

        if pixel_level:
            c = np.random.uniform(v_l, v_h, (h, w, img_c))
        else:
            c = np.random.uniform(v_l, v_h)

        input_img[top:top + h, left:left + w, :] = c

        return input_img
        
    def debug_img(self, img, depth, idx, i, prefix=''):
        from PIL import Image
        aug_img = Image.fromarray(np.clip(np.uint8(img*255), 0, 255))
        aug_img.save(prefix+str(idx)+"_"+str(i)+'.jpg',quality=99)
        aug_img = Image.fromarray(np.clip(np.uint8(np.tile(depth*255,3)), 0, 255))
        aug_img.save(prefix+str(idx)+"_"+str(i)+'.depth.jpg',quality=99)

'''
Models
'''
class BatchGenerator(Sequence):
    def __init__(self, 
                 image_list, 
                 batch_size, 
                 load_size, 
                 image_size, 
                 training=True,
                 augmentation=True,
                 normalize=True, 
                 shuffle=True):
        
        self.image_list = image_list
        self.batch_size = batch_size
        self.load_size = load_size
        self.image_size = image_size
        self.augmentation = augmentation
        self.training = training
        self.shuffle = shuffle
        self.normalize = normalize
        
        if self.shuffle: np.random.shuffle(self.image_list)
            
    def __len__(self):
        return int(np.ceil(len(self.image_list) / self.batch_size))
    
    def on_epoch_end(self):
        if self.shuffle: np.random.shuffle(self.image_list)
            
    def _augmentation(self, img):
        aug_img = np.array(img)
        
        # Gamma correction
        gamma = 0.6 * np.random.rand() + 0.7
        aug_img = np.clip(np.power(aug_img/255.0, gamma) * 255.0, 0, 255)
        
        return aug_img.astype(np.uint8)
            
    def __getitem__(self, idx):
        l_bound = idx * self.batch_size
        r_bound = (idx + 1) * self.batch_size
        
        if r_bound > len(self.image_list):
            r_bound = len(self.image_list)
            l_bound = r_bound - self.batch_size
            
        batch_images = self.image_list[l_bound:r_bound]
        batch_x = []
        for i in range(self.batch_size):
            im = Image.open(batch_images[i]).convert('RGB')
            
            if self.augmentation:
                im = self._augmentation(im)
                im = Image.fromarray(im)
            
            im = im.resize((self.load_size, self.load_size), Image.BILINEAR)
            
            w1, w2 = (self.load_size - self.image_size, self.load_size + self.image_size)
            h1, h2 = w1, w2
            
            img = np.array(im)[h1:h2, w1:w2, :]
            
            if self.training:
                if randint(0, 1):
                    img = img[:,::-1]
                
            if self.normalize:
                img = (np.array(img).astype(np.float32) / 255) * 2 - 1
            else:
                img = np.array(img)
            
            img = np.expand_dims(img, 0)
            batch_x.append(img)
        
        return np.vstack(batch_x)

def showX(X, imageSize, rows=1, do_display=None, display_path=None):
    assert X.shape[0]%rows == 0
    int_X = ( (X+1)/2*255).clip(0,255).astype('uint8')
    int_X = int_X.reshape(-1,imageSize,imageSize, 3)
    int_X = int_X.reshape(rows, -1, imageSize, imageSize,3).swapaxes(1,2).reshape(rows*imageSize,-1, 3)
    im = Image.fromarray(int_X.astype(np.uint8))
    im.save(display_path)
        

def showG(A,B, imageSize, cycleA_generate, cycleB_generate, do_display=False, display_path='test.png'):
    assert A.shape==B.shape
    def G(fn_generate, X):
        r = np.array([fn_generate([X[i:i+1]]) for i in range(X.shape[0])])
        return r.swapaxes(0,1)[:,:,0]        
    rA = G(cycleA_generate, A)
    rB = G(cycleB_generate, B)
    arr = np.concatenate([A,B,rA[0],rB[0],rA[1],rB[1]])
    showX(arr, imageSize, 3, do_display, display_path)

class ReflectionPadding2D(Layer):
    def __init__(self, padding=(1, 1), **kwargs):
        self.padding = tuple(padding)
        self.input_spec = [InputSpec(ndim=4)]
        super(ReflectionPadding2D, self).__init__(**kwargs)

    def compute_output_shape(self, s):
        """ If you are using "channels_last" configuration"""
        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])

    def call(self, x, mask=None):
        w_pad,h_pad = self.padding
        return tf.pad(x, [[0,0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')
    
class RandomCrop(Layer):
    def __init__(self, size, **kwargs):
        self.size = size
        self.input_spec = [InputSpec(ndim=4)]
        super(RandomCrop, self).__init__(**kwargs)

    def compute_output_shape(self, input_shape):
        """ If you are using "channels_last" configuration"""
        return (input_shape[0], 70, 70, 3)

    def call(self, x):
        return tf.random_crop(x, self.size)
    
class InstanceNormalization(Layer):
    """Instance normalization layer.
    Normalize the activations of the previous layer at each step,
    i.e. applies a transformation that maintains the mean activation
    close to 0 and the activation standard deviation close to 1.
    # Arguments
        axis: Integer, the axis that should be normalized
            (typically the features axis).
            For instance, after a `Conv2D` layer with
            `data_format="channels_first"`,
            set `axis=1` in `InstanceNormalization`.
            Setting `axis=None` will normalize all values in each
            instance of the batch.
            Axis 0 is the batch dimension. `axis` cannot be set to 0 to avoid errors.
        epsilon: Small float added to variance to avoid dividing by zero.
        center: If True, add offset of `beta` to normalized tensor.
            If False, `beta` is ignored.
        scale: If True, multiply by `gamma`.
            If False, `gamma` is not used.
            When the next layer is linear (also e.g. `nn.relu`),
            this can be disabled since the scaling
            will be done by the next layer.
        beta_initializer: Initializer for the beta weight.
        gamma_initializer: Initializer for the gamma weight.
        beta_regularizer: Optional regularizer for the beta weight.
        gamma_regularizer: Optional regularizer for the gamma weight.
        beta_constraint: Optional constraint for the beta weight.
        gamma_constraint: Optional constraint for the gamma weight.
    # Input shape
        Arbitrary. Use the keyword argument `input_shape`
        (tuple of integers, does not include the samples axis)
        when using this layer as the first layer in a Sequential model.
    # Output shape
        Same shape as input.
    # References
        - [Layer Normalization](https://arxiv.org/abs/1607.06450)
        - [Instance Normalization: The Missing Ingredient for Fast Stylization](
        https://arxiv.org/abs/1607.08022)
    """
    def __init__(self,
                 axis=None,
                 epsilon=1e-3,
                 center=True,
                 scale=True,
                 beta_initializer='zeros',
                 gamma_initializer='ones',
                 beta_regularizer=None,
                 gamma_regularizer=None,
                 beta_constraint=None,
                 gamma_constraint=None,
                 **kwargs):
        super(InstanceNormalization, self).__init__(**kwargs)
        self.supports_masking = True
        self.axis = axis
        self.epsilon = epsilon
        self.center = center
        self.scale = scale
        self.beta_initializer = initializers.get(beta_initializer)
        self.gamma_initializer = initializers.get(gamma_initializer)
        self.beta_regularizer = regularizers.get(beta_regularizer)
        self.gamma_regularizer = regularizers.get(gamma_regularizer)
        self.beta_constraint = constraints.get(beta_constraint)
        self.gamma_constraint = constraints.get(gamma_constraint)

    def build(self, input_shape):
        ndim = len(input_shape)
        if self.axis == 0:
            raise ValueError('Axis cannot be zero')

        if (self.axis is not None) and (ndim == 2):
            raise ValueError('Cannot specify axis for rank 1 tensor')

        self.input_spec = InputSpec(ndim=ndim)

        if self.axis is None:
            shape = (1,)
        else:
            shape = (input_shape[self.axis],)

        if self.scale:
            self.gamma = self.add_weight(shape=shape,
                                         name='gamma',
                                         initializer=self.gamma_initializer,
                                         regularizer=self.gamma_regularizer,
                                         constraint=self.gamma_constraint)
        else:
            self.gamma = None
        if self.center:
            self.beta = self.add_weight(shape=shape,
                                        name='beta',
                                        initializer=self.beta_initializer,
                                        regularizer=self.beta_regularizer,
                                        constraint=self.beta_constraint)
        else:
            self.beta = None
        self.built = True

    def call(self, inputs, training=None):
        input_shape = K.int_shape(inputs)
        reduction_axes = list(range(0, len(input_shape)))

        if self.axis is not None:
            del reduction_axes[self.axis]

        del reduction_axes[0]

        mean = K.mean(inputs, reduction_axes, keepdims=True)
        stddev = K.std(inputs, reduction_axes, keepdims=True) + self.epsilon
        normed = (inputs - mean) / stddev

        broadcast_shape = [1] * len(input_shape)
        if self.axis is not None:
            broadcast_shape[self.axis] = input_shape[self.axis]

        if self.scale:
            broadcast_gamma = K.reshape(self.gamma, broadcast_shape)
            normed = normed * broadcast_gamma
        if self.center:
            broadcast_beta = K.reshape(self.beta, broadcast_shape)
            normed = normed + broadcast_beta
        return normed

    def get_config(self):
        config = {
            'axis': self.axis,
            'epsilon': self.epsilon,
            'center': self.center,
            'scale': self.scale,
            'beta_initializer': initializers.serialize(self.beta_initializer),
            'gamma_initializer': initializers.serialize(self.gamma_initializer),
            'beta_regularizer': regularizers.serialize(self.beta_regularizer),
            'gamma_regularizer': regularizers.serialize(self.gamma_regularizer),
            'beta_constraint': constraints.serialize(self.beta_constraint),
            'gamma_constraint': constraints.serialize(self.gamma_constraint)
        }
        base_config = super(InstanceNormalization, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))

def general_conv2d(input_node, 
                   f, k, s, stddev=0.02, 
                   padding='valid', conv_id=0, use_batchnorm=True, use_relu=True, relu_alpha=0.):
    
    weights_initializer = tf.truncated_normal_initializer(stddev=stddev)
    biases_initializer = tf.constant_initializer(0.0)
    
    conv = Conv2D(f, k, strides=(s, s), 
                  padding=padding, 
                  kernel_initializer=weights_initializer,
                  bias_initializer=biases_initializer, 
                  name='general_conv2d_{}'.format(conv_id))(input_node)
    
    if use_batchnorm:
        conv = InstanceNormalization(epsilon=1e-5)(conv)
        
    if use_relu:
        if relu_alpha == 0.0:
            conv = Activation('relu')(conv)
        else:
            conv = LeakyReLU(alpha=relu_alpha)(conv)
            
    return conv

def general_deconv2d(input_node, 
                     f, k, s, stddev=0.02, 
                     padding='valid', conv_id=0, use_batchnorm=True, use_relu=True, relu_alpha=0.):
    
    weights_initializer = tf.truncated_normal_initializer(stddev=stddev)
    biases_initializer = tf.constant_initializer(0.0)
    
    deconv = Conv2DTranspose(f, k, strides=(s, s), 
                             padding=padding,
                             kernel_initializer=weights_initializer,
                             bias_initializer=biases_initializer,      
                             name='general_deconv2d_{}'.format(conv_id))(input_node)
    
    if use_batchnorm:
        deconv = InstanceNormalization(epsilon=1e-5)(deconv)
        
    if use_relu:
        if relu_alpha == 0.0:
            deconv = Activation('relu')(deconv)
        else:
            deconv = LeakyReLU(alpha=relu_alpha)(deconv)
    
    return deconv

def resnet_block(input_node, f, block_id=0):
    
    res = ReflectionPadding2D()(input_node)
    res = general_conv2d(res, f, 3, 1, conv_id=block_id)
    res = ReflectionPadding2D()(res)
    res = general_conv2d(res, f, 3, 1, conv_id=block_id+1)
    
    return add([input_node, res])

IMG_HEIGHT = 256
IMG_WIDTH = 256

IMG_CHANNELS = 3

POOL_SIZE = 50
ngf = 32
ndf = 64

lamb = 10

lrG = 2e-7
lrD = 2e-4

def __conv_init(a):
    print("conv_init", a)
    k = RandomNormal(0, 0.02)(a)
    k.conv_weight = True    
    return k

conv_init = RandomNormal(0, 0.02)
gamma_init = RandomNormal(1., 0.02)

'''
Discriminator
'''
def dcgan_discriminator(filters, nb_layers=3, use_sigmoid=True):
    
    input_node = Input(shape=(None, None, 3))
    x = Conv2D(filters, 
               kernel_size=4, 
               strides=(2, 2), 
               padding="same", 
               kernel_initializer=conv_init, 
               name='conv0')(input_node)
    x = LeakyReLU(alpha=0.2)(x)
    
    for layer in range(1, nb_layers):        
        f = filters * min(2**layer, 8)
        x = Conv2D(f, kernel_size=4, 
                   strides=(2, 2), 
                   padding="same", 
                   use_bias=False,
                   kernel_initializer=conv_init,
                   name = 'conv{0}'.format(layer)) (x)
        x = BatchNormalization(momentum=0.9, 
                               axis=-1, 
                               epsilon=1.01e-5,
                               gamma_initializer = gamma_init)(x, training=1)        
        x = LeakyReLU(alpha=0.2)(x)
    
    f = filters * min(2**nb_layers, 8)
    x = ZeroPadding2D(1)(x)
    x = Conv2D(f, kernel_size=4, use_bias=False, kernel_initializer=conv_init, name = 'conv{}'.format(nb_layers))(x)
    x = BatchNormalization(momentum=0.9, 
                           axis=-1, 
                           epsilon=1.01e-5,
                           gamma_initializer = gamma_init)(x, training=1) 
    x = LeakyReLU(alpha=0.2)(x)

    x = ZeroPadding2D(1)(x)
    x = Conv2D(1, kernel_size=4, use_bias=False, kernel_initializer=conv_init, name = 'conv{}'.format(nb_layers+1), 
               activation = "sigmoid" if use_sigmoid else None)(x)    
    return Model(input_node, x)

def discriminator_tf(input_size, k=4):
    
    input_node = Input(shape=(input_size, input_size, 3))
    c1 = general_conv2d(input_node, ndf, k, 2, padding='same', conv_id=0, use_batchnorm=False, relu_alpha=0.2)
    c2 = general_conv2d(c1, ndf * 2, k, 2, padding='same', conv_id=1, relu_alpha=0.2)
    c3 = general_conv2d(c2, ndf * 4, k, 2, padding='same', conv_id=2, relu_alpha=0.2)
    c4 = general_conv2d(c3, ndf * 8, k, 2, padding='same', conv_id=3, relu_alpha=0.2)
    c5 = general_conv2d(c4, 1, k, 2, padding='same', conv_id=4, use_batchnorm=False, use_relu=False)
    
    return Model(input_node, c5)

def patch_discriminator(input_size, k=4):
    
    input_node = Input(shape=(input_size, input_size, 3))
    patch_input = RandomCrop(size=[1, 70, 70, 3])(input_node)
    
    c1 = general_conv2d(patch_input, ndf, k, 2, padding='same', conv_id=0, use_batchnorm=False, relu_alpha=0.2)
    c2 = general_conv2d(c1, ndf * 2, k, 2, padding='same', conv_id=1, relu_alpha=0.2)
    c3 = general_conv2d(c2, ndf * 4, k, 2, padding='same', conv_id=2, relu_alpha=0.2)
    c4 = general_conv2d(c3, ndf * 8, k, 2, padding='same', conv_id=3, relu_alpha=0.2)
    c5 = general_conv2d(c4, 1, k, 2, padding='same', conv_id=4, use_batchnorm=False, use_relu=False)
    
    return Model(input_node, c5)

'''
Generator
'''
def generator_resnet_9blocks(input_size, skip=False):
    
    f = 7
    ks = 3
    
    input_node = Input(shape=(input_size, input_size, 3))
    x = ReflectionPadding2D(padding=(ks, ks))(input_node)
    
    # Downsampling layers
    x = general_conv2d(x, ngf, f, 1, conv_id=0)
    x = general_conv2d(x, ngf * 2, ks, 2, padding='same', conv_id=1)
    x = general_conv2d(x, ngf * 4, ks, 2, padding='same', conv_id=2)
    
    # Resnet blocks
    block_id = 3
    for _ in range(9):
        x = resnet_block(x, ngf * 4, block_id=block_id)
        block_id += 2
    
    # Upsampling layers
    x = general_deconv2d(x, ngf * 2, ks, 2, padding='same', conv_id=21)
    x = general_deconv2d(x, ngf, ks, 2, padding='same', conv_id=22)
    x = general_conv2d(x, IMG_CHANNELS, f, 1, padding='same', conv_id=23, use_batchnorm=False, use_relu=False)
    
    if skip:
        x = add([input_node, x])
    
    output_node = Activation(activation='tanh')(x)
    
    return Model(input_node, output_node)


def load_filelist(pattern):
    return glob(pattern)

"""Define Loss"""

from keras.optimizers import *

loss_fn = lambda output, target : K.mean(K.abs(K.square(output-target)))

def cycle_variables(netG1, netG2):
    real_input = netG1.inputs[0]
    fake_output = netG1.outputs[0]
    rec_input = netG2([fake_output])
    fn_generate = K.function([real_input], [fake_output, rec_input])
    return real_input, fake_output, rec_input, fn_generate

def lsgan_loss(netD, real, fake, rec):
    
    output_real = netD([real]) 
    output_fake = netD([fake]) 
    
    loss_D_real = loss_fn(output_real, K.ones_like(output_real))
    loss_D_fake = loss_fn(output_fake, K.zeros_like(output_fake))
    
    loss_D = loss_D_real + loss_D_fake
    loss_G = loss_fn(output_fake, K.ones_like(output_fake))
    loss_cyc = K.mean(K.abs(rec - real))
    
    return loss_D, loss_G, loss_cyc

import time

folder = '../output/examples/horse2zebra/'

if not os.path.isdir(folder):
    os.makedirs(folder)

def main():
    print("Starting execution")
    nb_epochs = 1
    gen_iterations = 0
    epoch = 0
    errCyc_sum = errGA_sum = errGB_sum = errDA_sum = errDB_sum = 0
    display_iters = 1

    starting_epoch_count = 0

    print("Creating Discriminators")

    """Discriminator objects"""
    dA = patch_discriminator(IMG_HEIGHT, k=4)
    dB = patch_discriminator(IMG_HEIGHT, k=4)

    print("Creating Generators")
    """Generator objects"""
    gA = generator_resnet_9blocks(IMG_HEIGHT)
    gB = generator_resnet_9blocks(IMG_HEIGHT)

    # Apply weights if available
    if os.path.isfile('./weights/horse2zebra/generatorA_weights.hdf5') and os.path.isfile('./weights/horse2zebra/generatorB_weights.hdf5'):
        print("Applying pre-loaded weights for generator")
        gA.load_weights('./weights/horse2zebra/generatorA_weights.hdf5')
        gB.load_weights('./weights/horse2zebra/generatorB_weights.hdf5')

    # Apply weights if available
    if os.path.isfile('./weights/horse2zebra/discriminatorA_weights.hdf5') and os.path.isfile('./weights/horse2zebra/discriminatorB_weights.hdf5'):
        print("Applying pre-loaded weights for discriminator")
        dA.load_weights('./weights/horse2zebra/discriminatorA_weights.hdf5')
        dB.load_weights('./weights/horse2zebra/discriminatorB_weights.hdf5')

    trainA_image_list = load_filelist('datasets/horse2zebra/trainA/*.jpg')
    trainB_image_list = load_filelist('datasets/horse2zebra/trainB/*.jpg')

    testA_image_list = load_filelist('datasets/horse2zebra/testA/*.jpg')
    testB_image_list = load_filelist('datasets/horse2zebra/testB/*.jpg')

    batch_size = 1

    batch_generatorA = BatchGenerator(trainA_image_list, batch_size, 287, 256)
    batch_generatorB = BatchGenerator(trainB_image_list, batch_size, 287, 256)

    test_generatorA = BatchGenerator(testA_image_list, batch_size, 287, 256)
    test_generatorB = BatchGenerator(testB_image_list, batch_size, 287, 256)

    print("Batches generated")

    #batch_generatorA.__getitem__(0)[0]
    real_A, fake_B, rec_A, cycleA_generate = cycle_variables(gB, gA)
    real_B, fake_A, rec_B, cycleB_generate = cycle_variables(gA, gB)

    loss_dA, loss_gA, loss_cycA = lsgan_loss(dA, real_A, fake_A, rec_A)
    loss_dB, loss_gB, loss_cycB = lsgan_loss(dB, real_B, fake_B, rec_B)

    cyc_loss = loss_cycA + loss_cycB
    d_loss = loss_dA + loss_dB
    g_loss = loss_gA + loss_gB + lamb * cyc_loss

    weightsD = dA.trainable_weights + dB.trainable_weights
    weightsG = gA.trainable_weights + gB.trainable_weights

    training_updates = Adam(lr=lrD, beta_1=0.5).get_updates(d_loss, weightsD)
    netD_train = K.function([real_A, real_B],[loss_dA/2, loss_dB/2], training_updates)

    training_updates = Adam(lr=lrG, beta_1=0.5).get_updates(g_loss, weightsG)
    netG_train = K.function([real_A, real_B], [loss_gA, loss_gB, cyc_loss], training_updates)

    print("Starting Epochs")
    # Commented out IPython magic to ensure Python compatibility.
    best_loss = np.Inf
    cycle_loss = 0

    idx1 = np.random.randint(0, len(testA_image_list))
    print(idx1)
    A = test_generatorA.__getitem__(idx1)
    idx2 = np.random.randint(0, len(testB_image_list))
    B = test_generatorB.__getitem__(idx2)


    showG(A, B, IMG_HEIGHT, cycleA_generate, cycleB_generate, do_display=False, display_path=folder + 'example_{}.png'.format(idx1))

    '''
    for epoch in range(nb_epochs):
        print('########### EPOCH %d ############' %(epoch))
        nb_steps = min(batch_generatorA.__len__(), batch_generatorB.__len__())
        for i in range(nb_steps):
            A = batch_generatorA.__getitem__(i)
            B = batch_generatorB.__getitem__(i)
            
            errDA, errDB  = netD_train([A, B])
            
            errDA_sum +=errDA
            errDB_sum +=errDB

            errGA, errGB, errCyc = netG_train([A, B])
            errGA_sum += errGA
            errGB_sum += errGB
            errCyc_sum += errCyc

            cycle_loss = errCyc_sum / (i+1)
        
            if i%display_iters==0:
                #if gen_iterations%(5*display_iters)==0:
                print('[%d/%d][%d/%d] Loss_D: %f %f Loss_G: %f %f loss_cyc %f'
                      % (epoch, nb_epochs, i, nb_steps, errDA_sum/display_iters, errDB_sum/display_iters,
                errGA_sum/display_iters, errGB_sum/display_iters, 
                errCyc_sum/display_iters))
                    
                A = test_generatorA.__getitem__(i)
                B = test_generatorB.__getitem__(i)
                showG(A,B, IMG_HEIGHT, cycleA_generate, cycleB_generate, do_display=False, display_path=folder + 'example_epoch_{}_step_{}.png'.format(starting_epoch_count+epoch, i))        
                errCyc_sum = errGA_sum = errGB_sum = errDA_sum = errDB_sum = 0
        
        # Shuffle data
        batch_generatorA.on_epoch_end()
        batch_generatorB.on_epoch_end()
        test_generatorA.on_epoch_end()
        test_generatorA.on_epoch_end()

        if (cycle_loss < best_loss):
            best_loss = cycle_loss
            print("Saving Weights")
            gA.save_weights('./weights/horse2zebra/generatorA_weights.hdf5')
            gB.save_weights('./weights/horse2zebra/generatorB_weights.hdf5')
            dA.save_weights('./weights/horse2zebra/discriminatorA_weights.hdf5')
            dB.save_weights('./weights/horse2zebra/discriminatorB_weights.hdf5')

    '''


if __name__ == "__main__":
    print("Starting CycleGAN execution")
    main()
